{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d3cf350",
   "metadata": {},
   "source": [
    "### Predictive Model for Estimating the Reach of a Training Institute on Social Media\n",
    "* **Business Objective:**\n",
    "The goal is to develop a predictive model that estimates the reach of a training instituteâ€™s social media campaigns. \n",
    "This will help in understanding how different social media activities impact the visibility and engagement of posts.\n",
    "\n",
    "* **Client Ref:** For any Social Media Platform\n",
    "* Features that can affect Reach,\n",
    "    - Social media info (Likes,Shares,Follwers,Type of Post etc...)\n",
    "* **Outcome:**\n",
    "* The predictive model will analyze historical data from social media platforms and estimate the expected reach of future posts using likes shares comments followers.\n",
    "* This will allow the training institute to optimize its campaigns for better engagement and visibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dd5a37",
   "metadata": {},
   "source": [
    "<img src=\"K.jpg\" width=600 height=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcf7391",
   "metadata": {},
   "source": [
    "### TOC <a class=\"anchor\" id=\"menu\"></a>\n",
    "\n",
    "\n",
    "* [0. Data Collection](#dc)\n",
    "* [1. Data Validation & Basic Cleaning](#dv)\n",
    "\n",
    "    @ Insights\n",
    "\n",
    "* [2. Data Understanding (EDA)](#eda)\n",
    "* [3. Missing Values & Outliers Handling](#naout)\n",
    "\n",
    "    @ Predictive Modeling\n",
    "* [4. Predictive Modeling (Machine Learning)](#pm)\n",
    "    * [4.1 X & y](#xy)\n",
    "    * [4.2 Feature Engineering](#fe)\n",
    "    * [4.3 Train-Test Split](#tt)\n",
    "    * [4.4 Model Selection & Training](#model)\n",
    "    * [4.5 & 4.6 Test Predictions & Evaluation](#eval)\n",
    "    * [4.7 Selecting Better Performance Model](#best)\n",
    "    * [4.8 Hypparam Tuning For Best Model(if required)](#hyp)\n",
    "    * [4.9 Saving Better Performance Model](#dep)\n",
    "    * [4.10 Real Time Prediction](#pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f10aa6",
   "metadata": {},
   "source": [
    "### 0. Data <a id=dc>\n",
    "    \n",
    "[Back to Top](#menu)\n",
    "\n",
    "* **For this project , We had taken manually collected dataset**\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bff8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Python Libraries - Data Manipulation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228e1300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data using pandas methods, with variable/object name 'raw'\n",
    "\n",
    "rawdata=pd.read_excel(\"smfinal.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b7d5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfffc73",
   "metadata": {},
   "source": [
    "### column info:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0dc7b7",
   "metadata": {},
   "source": [
    "| Column Name         | Description |\n",
    "|---------------------|-------------|\n",
    "| **Institute Name**  | Name of the institution offering the course. |\n",
    "| **CourseName**      | Name of the course being analyzed. |\n",
    "| **Platform**       | The platform where the course is being promoted (e.g., social media, websites). |\n",
    "| **Followers**       | The number of followers of the institution or course page. |\n",
    "| **type**           | The type/category of the course or post. |\n",
    "| **Likes**          | Number of likes received on the post. |\n",
    "| **Comments**       | Number of comments on the post. |\n",
    "| **Share**          | Number of times the post was shared. |\n",
    "| **Date**           | The date when the post was made. |\n",
    "| **Location**       | The location associated with the institute or course. |\n",
    "| **Interaction score** | A calculated score based on user interactions (likes, comments, shares, etc.). |\n",
    "| **Reach**          | Taken this column based on number of follwers,type of post,number of shares. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2d3e6b",
   "metadata": {},
   "source": [
    "* **Basic Checks of Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8085a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6313c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First five rows of Dataset:\")\n",
    "display(rawdata.head())\n",
    "\n",
    "print(\"Last five rows of Dataset:\")\n",
    "rawdata.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8e1021",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Column data Check (Null Values & Data Types):\")\n",
    "print()\n",
    "rawdata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716a6820",
   "metadata": {},
   "source": [
    "### 1. Data Validation & Cleaning <a id=dv>\n",
    "   \n",
    "[Back to Top](#menu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662d2d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking copy of data\n",
    "raw = rawdata.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fa8fca",
   "metadata": {},
   "source": [
    "* **Validating Each Column Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbc00eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42f49dd-90a4-44d2-8022-9d06f6337a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colcheck(df , col):\n",
    "    print(\"column: \", col)\n",
    "    print()\n",
    "    print(f\"Number Of Unique Values In Column:{df[col].nunique()}\")\n",
    "    print()\n",
    "    print(\"unique values in column:\")\n",
    "    print()\n",
    "    print(df[col].unique())\n",
    "    print()\n",
    "    print(\"data type of column:\" , df[col].dtype)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aab2e5b",
   "metadata": {},
   "source": [
    "                                        Institute Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b7b142",
   "metadata": {},
   "outputs": [],
   "source": [
    "colcheck(raw,'Institute Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e561c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw['Institute Name'].replace('\"@###\"',np.nan,inplace=True)\n",
    "raw['Institute Name'].replace('institute@@',np.nan,inplace=True)\n",
    "raw['Institute Name'].replace('nameof',np.nan,inplace=True)\n",
    "raw['Institute Name'].replace('Naaa',np.nan,inplace=True)\n",
    "raw['Institute Name'].replace('Nhu',np.nan,inplace=True)\n",
    "raw['Institute Name'].replace(' Labsji',np.nan,inplace=True)\n",
    "raw['Institute Name'].replace('new',np.nan,inplace=True)\n",
    "raw['Institute Name'].replace('insti',np.nan,inplace=True)\n",
    "raw['Institute Name'].replace('F#re',np.nan,inplace=True)\n",
    "raw['Institute Name'].replace('Institutename',np.nan,inplace=True)\n",
    "raw['Institute Name'].replace('Datafs',np.nan,inplace=True)\n",
    "raw['Institute Name'].replace('Vcube )8*6','Vcube Software Solutions',inplace=True)\n",
    "raw['Institute Name'].replace('Version iTt6yghb&&','Version iT',inplace=True)\n",
    "raw['Institute Name'].replace('Version iT***','Version iT',inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc36220f",
   "metadata": {},
   "outputs": [],
   "source": [
    "colcheck(raw,'Institute Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0be059",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw['Institute Name']=raw['Institute Name'].str.strip(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0254df0",
   "metadata": {},
   "source": [
    "                                        Course name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138edd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "colcheck(raw,'CourseName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172f1234",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw['CourseName'].replace('Dats',np.nan,inplace=True)\n",
    "raw['CourseName'].replace('Dlp',np.nan,inplace=True)\n",
    "raw['CourseName'].replace('Datam',np.nan,inplace=True)\n",
    "raw['CourseName'].replace('Dau',np.nan,inplace=True)\n",
    "raw['CourseName'].replace('AIhy',np.nan,inplace=True)\n",
    "raw['CourseName'].replace('Dataj',np.nan,inplace=True)\n",
    "raw['CourseName'].replace('AWji',np.nan,inplace=True)\n",
    "raw['CourseName'].replace('AWSmmm',np.nan,inplace=True)\n",
    "raw['CourseName'].replace('AWS^^',np.nan,inplace=True)\n",
    "raw['CourseName'].replace('AW66',np.nan,inplace=True)\n",
    "raw['CourseName'].replace('AW##',np.nan,inplace=True)\n",
    "raw['CourseName'].replace('AW%%',np.nan,inplace=True)\n",
    "raw['CourseName'].replace('dT',np.nan,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9625c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "colcheck(raw,'CourseName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0ea961",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw['CourseName']=raw['CourseName'].str.strip(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1a6b6e",
   "metadata": {},
   "source": [
    "                                            Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b803558",
   "metadata": {},
   "outputs": [],
   "source": [
    "colcheck(raw,'Platform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e67623",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw['Platform'].replace('rt',np.nan,inplace=True)\n",
    "raw['Platform'].replace('i',np.nan,inplace=True)\n",
    "raw['Platform'].replace('instagy',np.nan,inplace=True)\n",
    "raw['Platform'].replace('In',np.nan,inplace=True)\n",
    "raw['Platform'].replace('insta^^',np.nan,inplace=True)\n",
    "raw['Platform'].replace('kol',np.nan,inplace=True)\n",
    "raw['Platform'].replace('instl',np.nan,inplace=True)\n",
    "raw['Platform'].replace('insoooa',np.nan,inplace=True)\n",
    "raw['Platform'].replace('profile',np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581e135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw['Platform']=raw['Platform'].str.strip(' ')\n",
    "raw['Platform'].replace('insta','Insta',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9822f15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "colcheck(raw,'Platform')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d990e210",
   "metadata": {},
   "source": [
    "                                                    Followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d373a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "colcheck(raw,'Followers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a861790d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw['Followers'].replace('4#$',4,inplace=True)\n",
    "raw['Followers'].replace('12ed',12,inplace=True)\n",
    "raw['Followers'].replace('543op',543,inplace=True)\n",
    "raw['Followers'].replace('64%%',64,inplace=True)\n",
    "raw['Followers'].replace('561--',561,inplace=True)\n",
    "raw['Followers'].replace('111&',111,inplace=True)\n",
    "raw['Followers'].replace('33p1',33,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbbe5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "colcheck(raw,'Followers')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73beda32",
   "metadata": {},
   "source": [
    "                                            Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fec416",
   "metadata": {},
   "outputs": [],
   "source": [
    "colcheck(raw,'type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9433dd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw['type'].replace('po&&',np.nan,inplace=True)\n",
    "raw['type'].replace('rll',np.nan,inplace=True)\n",
    "raw['type'].replace('RE%%',np.nan,inplace=True)\n",
    "raw['type'].replace('POSi',np.nan,inplace=True)\n",
    "raw['type'].replace('eeio',np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac795e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "colcheck(raw,'type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7def69",
   "metadata": {},
   "outputs": [],
   "source": [
    "  raw.columns                                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508d20b1",
   "metadata": {},
   "source": [
    "                                                Likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25128f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "colcheck(raw,'Likes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0534c64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw['Likes'].replace('48lp',np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54973549",
   "metadata": {},
   "outputs": [],
   "source": [
    "colcheck(raw,'Likes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8adec8",
   "metadata": {},
   "source": [
    "                                        Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaab4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "colcheck(raw,'Comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755de18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw['Comments'].replace('0j',np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdea09be",
   "metadata": {},
   "outputs": [],
   "source": [
    "colcheck(raw,'Comments')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a590c0",
   "metadata": {},
   "source": [
    "                                                    Shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a269f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.columns=raw.columns.str.strip(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f25de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17c191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "colcheck(raw,'Share')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f980f02c",
   "metadata": {},
   "source": [
    "                                        Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d724cfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "colcheck(raw,'Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5b6894",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw['Date'].replace('29-01-200',np.nan,inplace=True)\n",
    "raw['Date'].replace('04-01---',np.nan,inplace=True)\n",
    "raw['Date'].replace('18-12-=',np.nan,inplace=True)\n",
    "raw['Date'].replace('10&&&',np.nan,inplace=True)\n",
    "raw['Date'].replace('09-10op',np.nan,inplace=True)\n",
    "raw['Date'].replace('07-02-20ui',np.nan,inplace=True)\n",
    "raw['Date'].replace('04-01-2tgn',np.nan,inplace=True)\n",
    "raw['Date'].replace('28*88',np.nan,inplace=True)\n",
    "raw['Date'].replace('31-01-202509',np.nan,inplace=True)\n",
    "raw['Date'].replace('&&',np.nan,inplace=True)\n",
    "raw['Date'].replace('10-09-2((',np.nan,inplace=True)\n",
    "raw['Date'].replace('28/10/20==',np.nan,inplace=True)\n",
    "raw['Date'].replace('22/1ll',np.nan,inplace=True)\n",
    "raw['Date'].replace('25/100024',np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be5f45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw['Day']=pd.to_datetime(raw['Date']).dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d048c886",
   "metadata": {},
   "outputs": [],
   "source": [
    "del raw['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc8f1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                raw.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e062b4d5",
   "metadata": {},
   "source": [
    "                                                    Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47623361",
   "metadata": {},
   "outputs": [],
   "source": [
    "colcheck(raw,'Location')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c27659f",
   "metadata": {},
   "source": [
    "                                                Reach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b10bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "colcheck(raw,'Reach')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a503e6-f642-4fc8-8cbb-c3e4acc3a68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb39c86",
   "metadata": {},
   "source": [
    "* All columns data is valid and data types are also proper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48df3613",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed97ec62",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d802b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in raw.columns:\n",
    "    if raw[col].dtype==object:\n",
    "        raw[col] = raw[col].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768b6250-e4af-45d8-a848-87ac2a77862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw[raw.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ef1b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw =  raw.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3d9998",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw[raw.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa809b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6fc143",
   "metadata": {},
   "source": [
    "### 2. EDA (Data Understanding)<a id=eda>\n",
    "    \n",
    "[Back to Top](#menu)\n",
    "\n",
    "* In EDA we can do Data Analysis in two methods\n",
    "    - Uni-Variate Analysis (Study of Individual column Data)\n",
    "        - Descriptive + Visual Analysis\n",
    "    - Bi-Varaite Analysis (Study data between two columns)\n",
    "        - Descriptive + Visual Analysis\n",
    "    - Multi-Variate Analysis (Study data between three or more columns)\n",
    "        - Descriptive Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e9e0da",
   "metadata": {},
   "source": [
    "### 2.1 Uni-Variate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35467102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viz Libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from plotly.offline import init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.express as px\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c7f3dd",
   "metadata": {},
   "source": [
    "* Taking user-defined module eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33390084-aff7-49a1-9a4b-43345a3ffb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptive_stats(df):\n",
    "    print(\"Statistical Summary of Numerical Columns:\\n\")\n",
    "    print(df.describe())\n",
    "    \n",
    "    print(\"\\nValue Counts for Categorical Columns:\\n\")\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        print(f\"Column: {col}\")\n",
    "        print(df[col].value_counts())\n",
    "        print(\"\\n\")\n",
    "descriptive_stats(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f6a90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_analysis(df):\n",
    "    for col in df.columns:\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        if df[col].dtype == 'object':  # Categorical columns\n",
    "            value_counts = df[col].value_counts()\n",
    "            if len(value_counts) < 5:  # Use pie chart for categorical columns with more categories\n",
    "                plt.figure(figsize=(6, 6))\n",
    "                value_counts.plot.pie(autopct='%1.1f%%')\n",
    "                plt.title(f'Pie Chart of {col}')\n",
    "                plt.ylabel('')\n",
    "            else:  # Use count plot for fewer categories\n",
    "                sns.countplot(x=df[col], order=value_counts.index)\n",
    "                plt.xticks(rotation=45)\n",
    "                plt.title(f'Count Plot of {col}')\n",
    "            plt.show()\n",
    "        else:  # Numerical columns\n",
    "            sns.histplot(df[col], kde=True, bins=30)\n",
    "            plt.title(f'Distribution of {col}')\n",
    "            plt.show()\n",
    "univariate_analysis(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4337e8f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e001166e",
   "metadata": {},
   "source": [
    "**Uni-Variate Insights**\n",
    "* There are 21 institutes data in the datset and more posts of naresh i techologies.\n",
    "* There are 9 different course posts or reels in data and more posts or reels on full stack development course.\n",
    "* Data is collected from instagram\n",
    "* Average follwers are 23126.\n",
    "* Most of the content is uploaded as post in social media.\n",
    "* Average likes are 52\n",
    "* There are minmum 0 and maximum 42 comments according to  data.\n",
    "* Average shares are 2 according to data.\n",
    "* Most of institutes data is from hyderabad.\n",
    "* Low reach is higher in count than other.\n",
    "* There are more number of posts or reels posted on tuesday."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f377a005",
   "metadata": {},
   "source": [
    "**2.2 Bi/Multi-Variate Analysis**\n",
    "- Descriptive Stats Measures used to study data between two or more columns.\n",
    "\n",
    "**Bi/Multi-Variate Combo**|**Stats Measures**\n",
    "----|-----------\n",
    "**Numeric-Numeric-..**|**Correlation (-1 to +1)**\n",
    "**Numeric-Categorical-..**|**Aggregation Functions (count, min, max, avg, sum)**\n",
    "**Categorical-Categorical-...**|**FDT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1342f273",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3761738c",
   "metadata": {},
   "source": [
    "                                                      Pure numeric\n",
    "                                        \n",
    "- To understand the data between number columns we can use correlation coeficient measure from descriptive stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c9241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considering followers and likes\n",
    "\n",
    "round(data[['Followers','Likes']].corr(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cf597a-0949-46f6-9dba-f9b766d5aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "px.scatter(data, x='Followers', y='Likes', trendline='ols', trendline_color_override='black', width=600, height=350)\n",
    "\n",
    "# data between two columns was shown in points in x & y axes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f91690-0fc9-4fa8-92f8-e7a63c0e0b61",
   "metadata": {},
   "source": [
    "Insights:\n",
    "* The data shows there is a weak positive correlation between Followers and Likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0389e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considering followers and likes\n",
    "\n",
    "round(data[['Share','Likes']].corr(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eede56ae-1c4f-46ca-9f49-12ebeae6fc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "px.scatter(data, x='Likes', y='Share', trendline='ols', trendline_color_override='black', width=600, height=350)\n",
    "\n",
    "# data between two columns was shown in points in x & y axes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18737966-bc64-4bc3-9a18-db9e3c945b7a",
   "metadata": {},
   "source": [
    "Insights:\n",
    "* The data shows that there is weak positive correlation between Likes and Shares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012864c1",
   "metadata": {},
   "source": [
    "                                                         Pure categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405d9fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Checking Categorical Columns\n",
    "\n",
    "data.select_dtypes(\"O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9a462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pandas df crosstab to get FDT between two columns\n",
    "pd.crosstab(data['Institute Name'], data['Reach'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10db76ec-c4e7-44f3-878a-8ba3a5a54eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(data,x='Institute Name',y='Reach')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b763721-2853-4725-b4bd-6a2911c224ed",
   "metadata": {},
   "source": [
    "Insights:\n",
    "* More posts or reels have low reach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a10ee60-a8b9-442b-a8f6-2eae1ae465a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use crosstab function in pandas to get FDT (Frequency Distribution Table) of each class\n",
    "\n",
    "print(\"CourseName vs Type:\")\n",
    "\n",
    "display(pd.crosstab(data['CourseName'], data['type'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c5a2c0-e8d0-4303-8611-d9d016e7948e",
   "metadata": {},
   "source": [
    "Insights:\n",
    "* There are more number of posts than reels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddbffe6",
   "metadata": {},
   "source": [
    "                                                             Mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3208c57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking pandas df groupby to get aggregations between above columns\n",
    "round(data.groupby('Institute Name')['Likes'].sum().sort_values(ascending=False),2) # Considering sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f77174-10dc-49e2-a66c-e544f4b7d666",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data, x=\"Institute Name\", y=\"Likes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccef8ff-6acc-4ad6-9aea-0af0c6bd7607",
   "metadata": {},
   "source": [
    "Insights:\n",
    "* Nxtwave disruptive technologies posts or reels have more number of likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd697086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking pandas df groupby to get aggregations between above columns\n",
    "round(data.groupby('CourseName')['Likes'].sum().sort_values(ascending=False),2) # Considering sum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8808e1-9d30-4d21-ad4c-45598408e889",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data, x=\"CourseName\", y=\"Likes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c7c19f-49f2-4b48-9dfc-8cca9204ed18",
   "metadata": {},
   "source": [
    "* AWS,Devops course has more number of likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7646b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484d92fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More than two columns\n",
    "\n",
    "data[['Institute Name','CourseName','Likes','Share']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227cbf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(data.groupby(['Institute Name','CourseName'])[['Likes', 'Share']].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039ede45",
   "metadata": {},
   "source": [
    "* **Insights::**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689e30b9",
   "metadata": {},
   "source": [
    "### Visualizations can be done along with Descriptive Stats for EDA\n",
    "- Visualizations are graphical representation of data with descriptive stats\n",
    "- Insights can be taken as same as descriptive stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a857ff",
   "metadata": {},
   "source": [
    "**In Python we can do visualization of data using below modules,**\n",
    "- Matplotlib\n",
    "- Pandas\n",
    "- Seaborn\n",
    "- Plolty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e427c46",
   "metadata": {},
   "source": [
    "* **Uni-Variate Graphs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae64850d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "25de76be",
   "metadata": {},
   "source": [
    "                                                 Catgeorical Col Data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "38248049",
   "metadata": {},
   "source": [
    "                                                    Pie chart\n",
    "\n",
    "        -> syntax: plt.pie(values, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d94cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Data: Category\n",
    "\n",
    "classes = data['CourseName'].value_counts().index\n",
    "vals = data['CourseName'].value_counts().values\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.pie(x = vals, labels = classes, autopct=lambda p:f'{p:.2f}%, ({p*sum(vals)/100 :.0f})', explode=[0.1, 0.1,0.1,0.1,0.1,0.2,0.1,0.1,0.1]) \n",
    "# use explode=[0.5, 0.1, 0.5, 0.1, 0.5, 0.1] for seperate pies (number of values are number of classes)\n",
    "plt.title(\"Course comparision\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e180f7",
   "metadata": {},
   "source": [
    "* **Insights:**\n",
    "    * Most of the institutes offer Full stack development course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9904f1f",
   "metadata": {},
   "source": [
    "                                                                Bar Chart\n",
    "    -> syntax: plt.bar(classes, vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38da008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Data: Region\n",
    "\n",
    "classes = data['Reach'].value_counts().index\n",
    "vals = data['Reach'].value_counts().values\n",
    "\n",
    "plt.style.use(\"dark_background\")\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.bar(classes, vals)\n",
    "plt.title(\"Comparission of Reach column\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c053a75-4430-4695-9000-ad6b62159972",
   "metadata": {},
   "source": [
    "* Most of posts or reels have low reach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82bb2b8-5b09-4b4a-a227-a58578db9db0",
   "metadata": {},
   "source": [
    "                                                     Numeric Col Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b675d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Data: Salary\n",
    "\n",
    "plt.hist(data['Share'])\n",
    "plt.title(\"Distribution of Shares in Social Media\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427a4e45",
   "metadata": {},
   "source": [
    "* **Bi-Variate Graphs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd30af7",
   "metadata": {},
   "source": [
    "                                                    N-N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6292be3f",
   "metadata": {},
   "source": [
    "                                                 Scatter Plot\n",
    "      -> syntax: plt.scatter(data,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aad3c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Column Data: Shares and Likes\n",
    "\n",
    "plt.scatter(data = data, x='Likes', y='Share', s=100, marker='*')\n",
    "plt.title(\"Likes and Shares of institutes in Social Media\")\n",
    "plt.xlabel(\"Likes\")\n",
    "plt.ylabel(\"Shares\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4efb7a3-6fdd-4420-b3b1-256ce440c0a0",
   "metadata": {},
   "source": [
    "* The data shows that there is weak positive correlation between Likes and Shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb55e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizontal Bargraph: \n",
    "# Column Data: Area\n",
    "data['Institute Name'].value_counts().sort_values(ascending=False)[0:10].plot(kind='barh', color='green', figsize=(6,5), title='Comparision ofInstitutes')                                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618b6e43-662a-4de5-90e0-eca041086e6f",
   "metadata": {},
   "source": [
    "* naresh i technologies institute have more number of posts or reels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600733a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot: \n",
    "# Column Data: Followers\n",
    "data['Followers'].plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35669976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kde plot: \n",
    "# Column Data:Comments\n",
    "data['Comments'].plot(kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b80df93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot : \n",
    "# Column Data: Shares Vs Likes with Reach\n",
    "\n",
    "sns.scatterplot(data=data, x='Likes', y='Share', hue='Reach')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23917a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e724e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data, hue='Reach') # For the hue we need to always take categorical col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a4253b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data.corr(numeric_only=True), annot=True, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f4ece2-48fe-4ad2-8870-bbfd1282b6e2",
   "metadata": {},
   "source": [
    "* There are no strong correlations found between numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db846f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3179e4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catplots: MultiVariate plots\n",
    "sns.catplot(data=data, y='type', x='Location', hue='Share', orient='h')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f546cd",
   "metadata": {},
   "source": [
    "**Overall Insights on Data**\n",
    "* **Uni-Variate Insights**\n",
    "* There are 21 institutes data in the datset and more posts of naresh i techologies.\n",
    "* There are 9 different course posts or reels in data and more posts or reels on full stack development course.\n",
    "* Data is collected from instagram\n",
    "* Average follwers are 23126.\n",
    "* Most of the content is uploaded as post in social media.\n",
    "* Average likes are 52\n",
    "* There are minmum 0 and maximum 42 comments according to  data.\n",
    "* Average shares are 2 according to data.\n",
    "* Most of institutes data is from hyderabad.\n",
    "* Low reach is higher in count than other.\n",
    "* There are more number of posts or reels posted on tuesday.\n",
    "* **Study of Data between two or more columns**\n",
    "* No Strong correlations found between numeric columns\n",
    "    * There is weak positive correlation between likes vs shares and followers vs likes\n",
    "* More posts or reels have low reach.\n",
    "* There are more number of posts than reels\n",
    "* Nxtwave disruptive technologies posts or reels have more number of likes\n",
    "* AWS,Devops course has more number of likes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99520500",
   "metadata": {},
   "source": [
    "### 3. Missing Values & Outlier Handling<a id=naout>\n",
    "    \n",
    "[Back to Top](#menu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eb3c0b",
   "metadata": {},
   "source": [
    "#### 3.1 Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889304ad",
   "metadata": {},
   "source": [
    "**Once we have a dataset collected, validated & analyzed, then before entering into predictive modeling we can do na & out handling , because most of the algorithms in predictive modeling can not accept missing values and also don't give better performance for outliers.**\n",
    "\n",
    "* We need to find and handle both of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569bcae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640a927e",
   "metadata": {},
   "source": [
    "* Empty values or any data point which is not belongs to column\n",
    "* Identify Missing Values\n",
    "    - Check for Standard & Non-Standard nan values \n",
    "* Handle the Missing Values\n",
    "    - Drop (Row, Column)\n",
    "    - Replace (MCT, Imputation, etc...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6f7c23",
   "metadata": {},
   "source": [
    "**a) Identification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a604db57",
   "metadata": {},
   "source": [
    "                                                     Column Wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42549e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas function for each column missing values count\n",
    "\n",
    "vdata.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5bdc9d",
   "metadata": {},
   "source": [
    "* All the columns are having missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aa81a6",
   "metadata": {},
   "source": [
    "* if any feature/column having more than 70% of the data missing then we can consider it for drop\n",
    "    - if we consider column importance for business then we need to replace values with variety of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2524dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Na count percentage for each column\n",
    "\n",
    "round((vdata.isnull().sum()/len(vdata))*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e3903b",
   "metadata": {},
   "source": [
    "                                                            Row\n",
    "\n",
    "* For the row wise drop , pick rows having missing values more than half of the columns\n",
    "* We can pick these rows and we can drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0435701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata[vdata.isnull().sum(axis=1)>=6]\n",
    "\n",
    "# we have 11 columns , considering 6 half of the cols data in row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194ade1b",
   "metadata": {},
   "source": [
    "* Rows Found with half missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab6179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### To Drop rows having more than half na values \n",
    "\n",
    "###### Taking Indexes of that rows\n",
    "\n",
    "allnaindx = vdata[vdata.isnull().sum(axis=1)>=6].index\n",
    "\n",
    "print(\"9 rows deleted\",len(allnaindx))\n",
    "\n",
    "##### Drop the above all na indx\n",
    "\n",
    "vdata = vdata.drop(allnaindx, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088f2e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e73ab8",
   "metadata": {},
   "source": [
    "* Check of missing values after drop method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09c3cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692ae552",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af879fcf",
   "metadata": {},
   "source": [
    "#### b.2) Replace \n",
    "    Replacing Missing Values can be done Col wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba85ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric columns replaced with median\n",
    "vdata.Followers.fillna(vdata.Followers.median(), inplace=True)\n",
    "vdata.Likes.fillna(vdata.Likes.median(), inplace=True)\n",
    "vdata.Comments.fillna(vdata.Comments.median(), inplace=True)\n",
    "vdata.Share.fillna(vdata.Share.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344aac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036bc165",
   "metadata": {},
   "source": [
    "###### categorical column null value replacement with least mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18c7f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata['Day'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58feb359",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata[vdata['Day'].isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a0e0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes11=vdata[vdata['Day'].isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01ba664",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(indexes11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedee71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata['Day'].iloc[indexes11[0:9]]='friday'\n",
    "vdata['Day'].iloc[indexes11[9:18]]='saturday'\n",
    "vdata['Day'].iloc[indexes11[18:]]='sunday'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ef4fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7601e300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first check for mode of that column\n",
    "vdata['Institute Name'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449fc31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata['Institute Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5e1127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 36 null values in Institute Name column(12+12+12=36)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aff0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata[vdata['Institute Name'].isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb9045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes=vdata[vdata['Institute Name'].isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e0cf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cbd8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1cd9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata['Institute Name'].iloc[indexes[0:12]]='besant technologies'\n",
    "vdata['Institute Name'].iloc[indexes[12:24]]='saidemy'\n",
    "vdata['Institute Name'].iloc[indexes[24:]]='social prachar'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85d85f1",
   "metadata": {},
   "source": [
    "                                                    CourseName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e887c6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata['CourseName'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2130134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata[vdata['CourseName'].isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4274e860",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes1=vdata[vdata['CourseName'].isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80405ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(indexes1) # 54=18+18+18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c702acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata['CourseName'].iloc[indexes1[0:18]]='gcp'\n",
    "vdata['CourseName'].iloc[indexes1[18:36]]='ds'\n",
    "vdata['CourseName'].iloc[indexes1[36:]]='dataskills'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7144a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87d9e96",
   "metadata": {},
   "source": [
    "                            platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594c152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata['Platform'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dd7580",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata.Platform.fillna(vdata.Platform.mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f6b0ab67",
   "metadata": {},
   "source": [
    "                        type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1b0327",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0421640c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata[vdata['type'].isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33402a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes23=vdata[vdata['type'].isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c523e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(indexes23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bc5a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata['type'].iloc[indexes23[0:20]]='reel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab33ab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e984ddee",
   "metadata": {},
   "source": [
    "                                        Reach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11855587",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata['Reach'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd7bf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata[vdata['Reach'].isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea5a069",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes45=vdata[vdata['Reach'].isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da43c1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(indexes45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835d4264",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata['Reach'].iloc[indexes45[0:97]]='moderate'\n",
    "vdata['Reach'].iloc[indexes45[97:194]]='high'\n",
    "vdata['Reach'].iloc[indexes45[194:]]='low'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531a9002",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2818ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6230f5",
   "metadata": {},
   "source": [
    "**3.2 Outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b404c362",
   "metadata": {},
   "outputs": [],
   "source": [
    "from outlier import outlier_detect, outlier_replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba1d743",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcols = outlier_detect(vdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758b88fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_replacement(vdata, outcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd97d98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Check of Outliers\n",
    "\n",
    "outlier_detect(vdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba14f0f6",
   "metadata": {},
   "source": [
    "* Almost all the outliers in columns are replaced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fed808f",
   "metadata": {},
   "source": [
    "### 4. Predictive Modeling<a id=pm>\n",
    "    \n",
    "[Back to Top](#menu)\n",
    "    \n",
    "* Building a predictive model/trained algorithm to get the relation betweeen one col(y) to other columns (X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edf4a68",
   "metadata": {},
   "source": [
    "#### 4.1 Selecting X & y <a id=xy>\n",
    "    \n",
    "[Back to Top](#menu)\n",
    "\n",
    "* Selecting Output column (y) - future prediction column & Input column/columns (X) - Reference columns\n",
    "\n",
    "    -  X (independent variables/input columns/explanatory variables)\n",
    "    - y (dependent variable/output column/response column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8c652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdata.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83ac3cd",
   "metadata": {},
   "source": [
    "* For this we dataset we want to predict Class Reach, taking **Reach column as Output (y)**\n",
    "    - **Remaining Columns data can be taken as input (X)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eef058",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(columns=['B', 'C'])\n",
    "#X=vdata.drop(columns=['Platform','Likes','Comments','Share','Reach'])\n",
    "X=vdata[['Institute Name','CourseName','Followers','type','Location','Day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fb3fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=vdata['Reach']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c210336",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02c5157",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d3e3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Input Columns Data (X):\")\n",
    "display(X.head())\n",
    "print()\n",
    "print(\"Output Column Data (y):\")\n",
    "display(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cfac73",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dead5e5",
   "metadata": {},
   "source": [
    "y column is balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528f94c8",
   "metadata": {},
   "source": [
    "#### 4.2  Feature Engineering of X<a id=fe>\n",
    "\n",
    "[Back to Top](#menu)\n",
    "\n",
    "* Generation/ Modification / Deletion / Selection of X columns/features according to y column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aadd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548a5f52",
   "metadata": {},
   "source": [
    "* Need to handle Institute Name,Course name,type,Location,Date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b4c503",
   "metadata": {},
   "source": [
    "#### 4.2.1 Feature Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd137a1f",
   "metadata": {},
   "source": [
    "* Done in Data validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff038220",
   "metadata": {},
   "source": [
    "#### 4.2.2 Feature Selection/Deletion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a46cbd7",
   "metadata": {},
   "source": [
    "**Considering all the  columns for predictive modeling, as each column has its own importance to Reach**\n",
    "\n",
    "* If the model performance is not ok, then we can comeback to this step and we can select imp x features using statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd4152d-13ef-48a5-815a-fcdaaa923593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Data for UserInput\n",
    "X.to_csv(\"inputdata.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1345b549-3052-414a-8422-ae9c69395a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb60ed3-da7c-40e1-944b-3a2a5bd98d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189870ae",
   "metadata": {},
   "source": [
    "#### 4.2.3 Feature Modification (Data Pre-Processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f623e4d",
   "metadata": {},
   "source": [
    "**Encoding**\n",
    "\n",
    "* Converting categorical data to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42e1a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Categorical Data\n",
    "X.select_dtypes(\"O\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b5de32",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = X.select_dtypes(\"O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5da2edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bb53e4",
   "metadata": {},
   "source": [
    "* **Checking number of categories in above columns and applying encoding techniques**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd63a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    print(col, \":\", cat_cols[col].nunique())\n",
    "    print(cat_cols[col].unique())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36dc014",
   "metadata": {},
   "source": [
    "* From above, each column is having more than two classes except platform,type,location\n",
    "* Need to Identify ordinal and nominal columns to apply proper encoding\n",
    "    - Ordinal Encoding - for Ordinal Cols\n",
    "    - One-Hot Encoding - for Nominal Cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeeb0d3",
   "metadata": {},
   "source": [
    "* From Business Pov we can consider,\n",
    "\n",
    "      Binary columns: type,location\n",
    "      Ordinal columns: Day,course name\n",
    "      Nominal columns: institute name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbc2eac",
   "metadata": {},
   "source": [
    "                               Binary encoding-- type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b60e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5a73c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.type.replace({'post':0,'reel':1}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05368cd4",
   "metadata": {},
   "source": [
    "                            Binary encoding-location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5135ca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.Location.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6ae68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.Location.replace({'hyderabad':0,'banglore':1}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98bafbf",
   "metadata": {},
   "source": [
    "* **Ordinal Columns Data Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157d7c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[['Day','CourseName']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a048c03b",
   "metadata": {},
   "source": [
    "* We can replace above cat classes with ordinal numbers, \n",
    "    - Those numbers can be,\n",
    "        - target encoding: output column value according to class or\n",
    "        - ordinal number according to alphabetical order\n",
    "        - or our own choice of numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790b7d1d",
   "metadata": {},
   "source": [
    "* **for the above ordinal cols considering target encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0629eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing a loop\n",
    "\n",
    "import pickle # Module to save encoding dictionaries\n",
    "\n",
    "for col in X[['Day','CourseName']].columns:\n",
    "    # Taking value counts of each class as it represents sum of yes and no values of output column\n",
    "    grouped = X[col].value_counts()\n",
    "    ordencoding = {brand:value for brand, value in zip(grouped.index, grouped.values)}\n",
    "    # saving above encoding for future use\n",
    "    with open(f'{col}_encoding.pkl', 'wb') as f:\n",
    "        pickle.dump(ordencoding, f)\n",
    "        \n",
    "    X[col].replace(ordencoding, inplace=True)    \n",
    "    \n",
    "# To load encoding for future use \n",
    "\n",
    "# with open('saved_dictionary.pkl', 'rb') as f:\n",
    "#     loaded_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a87cb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc37702",
   "metadata": {},
   "source": [
    "* **Nominal Column Data Encoding**      - **Institute name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d076e925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Define Object\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# handle_unknown=ignore -> future classes will be ignored\n",
    "# drop=first -> is another param for dummy variable trap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532c5ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using fit_transform method to convert column data into onehot encodings\n",
    "\n",
    "ohedata = ohe.fit_transform(X[['Institute Name']]).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945a1073",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohedata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54580eb",
   "metadata": {},
   "source": [
    "* Adding above one hot encoded data to X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e9d26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to dataframe\n",
    "\n",
    "ohedata = pd.DataFrame(ohedata, columns=ohe.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8d6209",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fcc11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping  CourseName , Platform with Ohedata\n",
    "\n",
    "X = pd.concat([X.drop(['Institute Name'], axis=1), ohedata], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcfeb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65b9a47",
   "metadata": {},
   "source": [
    "**Scaling**\n",
    "\n",
    "* Converting main numeric columns under one scale if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92ea62b",
   "metadata": {},
   "source": [
    "* Scaler Suggested if columns data is on different scales\n",
    "    - Standard Scaler (-3 to +3)\n",
    "    - Robust Scaler (When we have outliers in columns)\n",
    "    - MinMaxScaler (-1 to +1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bd7562",
   "metadata": {},
   "source": [
    "* Numeric Cols are in different scales , need to apply scaling\n",
    "    - Followers,Likes,Comments,share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e4b780",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.iloc[:,[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165944c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "X.iloc[:,[1]] = sc.fit_transform(X.iloc[:,[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0242fdcf",
   "metadata": {},
   "source": [
    "* **Final X Data for modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db86ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59dcca9",
   "metadata": {},
   "source": [
    "* **y data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6056b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f8f7ef",
   "metadata": {},
   "source": [
    "#### 4.3 Train-Test Split of X & y<A id=tt>\n",
    "    \n",
    "[Back to Top](#menu)\n",
    "    \n",
    "* Dividing data into two parts, train-test\n",
    "    - train part used for model building\n",
    "    - test part is used for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d06dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn method\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.30, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9118b25f-a5ab-4400-a114-71908abf310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain.shape, ytrain.shape  # model training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e11b8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6770bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e41702b-7388-450a-9a6d-0e9ccd581592",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest.shape, ytest.shape # model evaluation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2726b7cd-58ef-4679-8eb1-0998d4d028aa",
   "metadata": {},
   "source": [
    "**4.4 Modeling/Algorithm Training on Train Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b634dd0-09a1-4448-ab1a-b71ca6c49ad7",
   "metadata": {},
   "source": [
    "* Sending xtrain & ytrain data to a algorithm, where it can study the patterns and gives predictive model to generate y for future x values\n",
    "\n",
    "* Taken **y data is categorical**, we can apply **machine learning supervised classification algorithms**\n",
    "    \n",
    "* In Classification we have below algorithms\n",
    "    - Logistic Regression\n",
    "    - Knearest Neighbors (KNN)\n",
    "    - Support Vector Machine (SVM)\n",
    "    - Naive Bayes (NB)\n",
    "    - Decision Trees (CART)\n",
    "    - Random Forest (Bagging)\n",
    "    - Xgboost (Boosting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bda6d04-d8b0-4a4a-aea3-fe0edd13ba38",
   "metadata": {},
   "source": [
    "* Importing Sklearn Library Models Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d694bf79-0d59-4af8-a74d-2f281bfe43a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b5eb83-8ede-4ab0-9ceb-a99fb73c20c2",
   "metadata": {},
   "source": [
    "* Model Objects Defining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c976ae76-ae30-4911-88fd-5cdec432a430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Define\n",
    "\n",
    "log = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "knn = KNeighborsClassifier(n_neighbors=5, p=1)\n",
    "\n",
    "# Here neighbors are the hyperparameter\n",
    "# Distance is the another hyperparameter (p) 2 for euclidean distance\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "dt = DecisionTreeClassifier() # Taking default Hyper params\n",
    "\n",
    "# We can try hyp params:\n",
    "# criteria is the root node selection method\n",
    "# max_depth is the number of subtrees in decision  tree - main Hyperparameter\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,  # Number of trees\n",
    "    max_depth=20,      # Maximum depth of trees\n",
    "    min_samples_split=5, # Minimum samples required to split a node\n",
    "    min_samples_leaf=2,  # Minimum samples required at a leaf node\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model on your training data\n",
    "# Taking Default Hyp params\n",
    "\n",
    "# We can try hyp params:\n",
    "# n_estimators are number of decision trees - Hyper parameter\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "sv = SVC(kernel = 'rbf', gamma=5) # for a non-linear seperable data\n",
    "\n",
    "# Gamma=Sigma=coeffient for the rbf kernel - hyperparameter\n",
    "# Kernel linear-- Linear SVM\n",
    "#sv = SVC(kernel=\"linear\") # for a linear separable data\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "nb = GaussianNB()\n",
    "    \n",
    "# -----------------------------------------------------------\n",
    "xgb = XGBClassifier() # Taking default Hyper params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b08051-4938-4c40-844e-33d4c23e62f1",
   "metadata": {},
   "source": [
    "**Model Training**\n",
    "\n",
    "* Using xtrain, ytrain data\n",
    "* Using fit command to train the defined model with xtrain, ytrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebeef5bd-54e0-465a-a5ab-ea899243cdbb",
   "metadata": {},
   "source": [
    "**4.4.1 Logistic Regression**\n",
    "\n",
    "* \n",
    "It uses the Linear Regression line to convert it into a sigmoid curve with the logit function output as probability of class\n",
    "\n",
    "prob = 1/1+e^-y\n",
    "\n",
    "if prob>0.5 1 \n",
    "else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdef3e93-1bd4-443d-893d-12dd3a050b08",
   "metadata": {},
   "source": [
    "* Learning/Training Model on train data\n",
    "* \n",
    "we can use fit function in model for xtrain and ytrain data to train our data for getting the line co-efficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecee2f0-34ba-4f6d-b868-94b9e0a97bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "log.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482bbf99-cf9f-4e5d-896d-f3af24f4933d",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b803ad5b-bb3e-4cb8-b37e-071b9b8f6779",
   "metadata": {},
   "outputs": [],
   "source": [
    "log.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5791ca8-490d-4ae2-8e72-33ca4047098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ae0a66-ab4f-49f5-8eb1-77fc9a05cab1",
   "metadata": {},
   "source": [
    "**4.4.2 KNN - K Nearest Neighbors**\n",
    "* It will take the nearest data points using euclidean distance metric with number of k given\n",
    "\n",
    "* It is a lazy algorithm , it wont train the data instead it will store the data\n",
    "\n",
    "* It will do the training when test data given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125731ac-d56c-4f18-b6c7-243fb6cb28c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8422df0a-eb24-4ebd-bcc9-4ca5af5d79c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc87ac9-2ebd-43a1-b851-ad3629285290",
   "metadata": {},
   "source": [
    "**4.4.3 Decision Tree**\n",
    "* Logic Tree based predictions based on root and interior nodes, branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6298ddd1-0b5c-4974-bc51-9d7437a6384c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e529d3-cace-4540-a265-af1e92dee7a5",
   "metadata": {},
   "source": [
    "* **Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3848d00d-f56e-4724-bd66-bda76333805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(index = dt.feature_names_in_,data = [round(val,2) for val in dt.feature_importances_], columns = ['FeatureImportance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afae07d5-bdad-4c6b-b764-26623f61101b",
   "metadata": {},
   "source": [
    "* **Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d1d03d-b956-491f-95a4-c79de177d7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0637b5d6-ea18-4038-b89b-49983860364e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (30,30), dpi = 150)\n",
    "plot_tree(dt,filled = True, feature_names=list(xtrain.columns))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9fb622-d9b9-4cfe-9dfc-90fe12e1a218",
   "metadata": {},
   "source": [
    "**4.4.4 Random Forest**\n",
    "* Bagging algorithm which was a combination of Multiple Decision Trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6f6227-92f5-44cc-ade0-77ceaa67bef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c7aae1-60fc-4f30-81aa-a7dfaebf5871",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(index = rf.feature_names_in_,data = [round(val,2) for val in rf.feature_importances_], columns = ['FeatureImportance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82267b1-95cc-4846-be61-53821d6ccc5d",
   "metadata": {},
   "source": [
    "* Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a096432-b535-4e44-8bb8-50ed73f29989",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24627103-f2de-46e3-90f0-401ed7c5bb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,10),dpi = 150)\n",
    "plot_tree(rf.estimators_[1],filled = True, feature_names=xtrain.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddaffe4-cf2d-4799-8ffd-355d0d789de1",
   "metadata": {},
   "source": [
    "**4.4.5 SVM (Time Taking for Higher Dimensional Data)**\n",
    "* Support vectors (Data Points grouped with Soft Margin Classifier) - for linear data\n",
    "\n",
    "* for non-linear data kernel trick is used to divide classes - rbf , poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c2198c-b45a-4655-84ef-da0c91c81238",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca53eb58-8aee-49d3-89e0-7b9d6abbfa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sv.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de8b02f-4bab-4f82-818e-a45b64d3bb72",
   "metadata": {},
   "source": [
    "**4.4.6 Naive Bayes**\n",
    "* Naive Bayes works on Bayesian Probability formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609ff128-71a6-4bfc-b3c6-7fa5bcb1d4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40131d47-9dc7-4afd-b957-876a7c5e22ff",
   "metadata": {},
   "source": [
    "**4.4.7 Xgboost**\n",
    "* Boosting Algorithm where for the selected number of models , one model error will be trained by another model\n",
    "\n",
    "  We need to install xgboost, using anaconda prompt - pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62810f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "ytrain_xg = le.fit_transform(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885cbe0f-3a05-42fc-8181-14fa5db5389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost accepts label data as number\n",
    "\n",
    "ytrain_xg = np.where(ytrain == 'low', 0, np.where(ytrain == 'moderate', 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fee03c2-b303-49ab-a325-edcf1ba8dd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(xtrain,ytrain_xg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a22180-d9ad-4d16-b0d0-94e39430048f",
   "metadata": {},
   "source": [
    "**4.5 Test Predictions & 4.6 Model Evaluation/Performance**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73aded8e-3ca1-496c-830e-fed7e942149e",
   "metadata": {},
   "source": [
    "* Checking Trained Model Performances on Test Data\n",
    "\n",
    "* Using x_test data we will be getting predictions, these predictions will be compared to y_test\n",
    "\n",
    "* To check Model Performance we can use evaluation methods\n",
    "\n",
    "    * Error/Loss\n",
    "    * Model Score \n",
    "    * Bias-Variance Trade off (Underfit or Overfit)\n",
    "    * Cross-Val Score\n",
    "\n",
    "* **For classification we can use these evaluation**\n",
    "    \n",
    "\n",
    "\n",
    "Performance Metric | Classification\n",
    "-------|-----------\n",
    "**Loss or Error**|**Confusion Matrix (Number of right/wrong predictions)**\n",
    "**Model Score (Evaluation)** | **Accuracy Score (Balanced Data) , F1-Score/Auc-Roc Score (For Imbalanced Data)**\n",
    "**Bias-Variance Trade Off**|Higher error & Lower score (underfit)\n",
    "-|Low Train error & High Test error (Overfit)\n",
    "**Cross-Val Score**|Checking trained model performance on entire X and y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210493d1-dcda-4528-9a4f-9be7e3264976",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144d0ee7-3ca7-49fa-94bd-d6215f195e99",
   "metadata": {},
   "source": [
    "* **As we have nearly balanced data considering accuracy score for understanding model performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad67ae06-5c27-4e5e-b318-4a4ffdafc980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules for Metrics\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, roc_curve, roc_auc_score, auc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tabulate import tabulate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41d74bd-96bc-4174-b0d3-59d063c2dd12",
   "metadata": {},
   "source": [
    "* **Checking the above models perfomance using Test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbf1f75-859f-4fa0-8273-3384b059149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['LogisticRegression', 'KNearestNeighbors', 'SVM', 'Naive Bayes', 'Decision Tree', 'Random Forest', 'Xgboost']\n",
    "\n",
    "models = {'log':log,'knn':knn,'svm':sv, 'nb':nb, 'dt':dt, 'rf':rf, 'xgb':xgb}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2fd20a-e1e1-4e52-be52-8d90302376a3",
   "metadata": {},
   "source": [
    "* **Confusion_matrix , Classification_report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd60c6c-1c77-4538-87ea-cb7004eb0643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_colors import *\n",
    "\n",
    "n=0\n",
    "for key,value in models.items():\n",
    "    print(green(\"Model: {}\\n\".format(names[n]),['bold']))\n",
    "    if key == 'xgb':\n",
    "        ytest_pred = models[key].predict(xtest)\n",
    "        ytest_xg = np.where(ytest == 'low', 0, np.where(ytest == 'moderate', 1, 2))\n",
    "        print(\"Classification Report:\\n\",classification_report(ytest_xg, ytest_pred))\n",
    "        print(blue(\"Confusion_Matrix:\",['bold']))\n",
    "        plt.show(ConfusionMatrixDisplay.from_estimator(models[key], xtest, ytest_xg))\n",
    "        print(\"-----------------------------------------------------------------------------------\")\n",
    "    else:\n",
    "        ytest_pred = models[key].predict(xtest.values)\n",
    "        print(\"Classification Report:\\n\",classification_report(ytest, ytest_pred))\n",
    "        print(blue(\"Confusion_Matrix:\",['bold']))\n",
    "        plt.show(ConfusionMatrixDisplay.from_estimator(models[key], xtest.values, ytest))\n",
    "        print(\"-----------------------------------------------------------------------------------\")\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff98e65c-e80c-43e5-87f4-3f1626e67f52",
   "metadata": {},
   "source": [
    "**Making Table for accuracy scores of all the models for train and test data to decide best model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e1dd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name == 'xgb':\n",
    "        # Processing for XGBoost model\n",
    "        ytrain_xg = np.where(ytrain == 'low', 0, np.where(ytrain == 'moderate', 1, 2))\n",
    "        ytest_xg = np.where(ytest == 'low', 0, np.where(ytest == 'moderate', 1, 2))\n",
    "\n",
    "        ytrain_pred = model.predict(xtrain)\n",
    "        ytest_pred = model.predict(xtest)\n",
    "\n",
    "        # Accuracy Score\n",
    "        trscore = round(accuracy_score(ytrain_xg, ytrain_pred), 2)\n",
    "        tescore = round(accuracy_score(ytest_xg, ytest_pred), 2)\n",
    "\n",
    "        # Bias-Variance Trade off\n",
    "        if trscore < 0.50 and tescore < 0.50:\n",
    "            if abs(trscore) == 0 and abs(tescore) == 0:\n",
    "                fit = \"Nofit\"\n",
    "            else:\n",
    "                fit = \"Underfit\"\n",
    "        else:\n",
    "            if abs(trscore - tescore) < 0.10:\n",
    "                fit = \"Goodfit\"\n",
    "            elif abs(trscore - tescore) >= 0.10:\n",
    "                fit = \"Overfit\"\n",
    "            else:\n",
    "                fit = \"Fit\"\n",
    "\n",
    "        y_xg = np.where(y == 'low', 0, np.where(y == 'moderate', 1, 2))\n",
    "\n",
    "        # Cross-val score\n",
    "        scores = cross_val_score(model, X, y_xg, cv=2, scoring='f1_micro')\n",
    "        crossvalscore = round(scores.mean(), 2)\n",
    "\n",
    "    else:\n",
    "        # Processing for other models\n",
    "        ytrain_pred = model.predict(xtrain.values)\n",
    "        ytest_pred = model.predict(xtest.values)\n",
    "\n",
    "        # Accuracy Score\n",
    "        trscore = round(accuracy_score(ytrain, ytrain_pred), 2)\n",
    "        tescore = round(accuracy_score(ytest, ytest_pred), 2)\n",
    "\n",
    "        # Bias-Variance Trade off\n",
    "        if trscore < 0.50 and tescore < 0.50:\n",
    "            if abs(trscore) == 0 and abs(tescore) == 0:\n",
    "                fit = \"Nofit\"\n",
    "            else:\n",
    "                fit = \"Underfit\"\n",
    "        else:\n",
    "            if abs(trscore - tescore) < 0.10:\n",
    "                fit = \"Goodfit\"\n",
    "            elif abs(trscore - tescore) >= 0.10:\n",
    "                fit = \"Overfit\"\n",
    "            else:\n",
    "                fit = \"Fit\"\n",
    "\n",
    "        # Cross-val score\n",
    "        scores = cross_val_score(model, X.values, y, cv=2, scoring='f1_micro')\n",
    "        crossvalscore = round(scores.mean(), 2)\n",
    "\n",
    "    # Append results\n",
    "    results.append([name, f\"{trscore:.4f}\", f\"{tescore:.4f}\", f\"{crossvalscore:.4f}\", fit])\n",
    "# Print the results in a tabular format\n",
    "print(tabulate(results, headers=[\"Model\", \"Train Accuracy\", \"Test Accuracy\", \"Cross-Validation Score\", \"Model Fit\"], tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a54509",
   "metadata": {},
   "source": [
    "**4.7 Best Model**<a id='best'>\n",
    "    \n",
    "[Back to Top](#menu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9432368a",
   "metadata": {},
   "source": [
    "* From the Observation of above results based on test score\n",
    "\n",
    "    * **logistic regression,random forest is better when compared to others**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967615c9",
   "metadata": {},
   "source": [
    "**4.8 Hyp Param Tuning**<a id='hyp'>\n",
    "    \n",
    "[Back to Top](#menu)\n",
    "\n",
    "* doing hyper parameter tunning for random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd776fc",
   "metadata": {},
   "source": [
    "**4.9 Saving Model**<a id='dep'>\n",
    "    \n",
    "[Back to Top](#menu)\n",
    "                                                    \n",
    "- Saving Trained & Evaluated model for future predictions\n",
    "    - From above training we need to save objects\n",
    "    - In python we have libraries , joblib, pickle to save model files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c8e1d9",
   "metadata": {},
   "source": [
    "#### 4.10 Realtime Prediction<a id='pred'>\n",
    "\n",
    "[Back to Top](#menu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8946a7b-2445-44d5-ae2d-167ccced095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Saving trained model\n",
    "joblib.dump(log, 'logistic.pkl')\n",
    "# Saving onehot encoded model\n",
    "\n",
    "joblib.dump(ohe, 'ohe.pkl')\n",
    "\n",
    "\n",
    "joblib.dump(sc, \"sc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f29b29-0d46-4133-9716-a209209971bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading saved pickles and getting predictions\n",
    "\n",
    "import joblib\n",
    "log= joblib.load('logistic.pkl')\n",
    "feature_names = log.feature_names_in_.tolist()\n",
    "\n",
    "sc = joblib.load(\"sc.pkl\")\n",
    "\n",
    "# Loading Saved object files\n",
    "ohe = joblib.load('ohe.pkl')\n",
    "   \n",
    "\n",
    "# Loading Saved Ordinal Encoded files\n",
    "with open('Day_encoding.pkl', 'rb') as f:\n",
    "    Day_encoding = pickle.load(f)\n",
    "    \n",
    "with open('CourseName_encoding.pkl', 'rb') as f:\n",
    "    CourseName_encoding = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3ac76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def ReachinSocialMedia_Prediction():\n",
    "    print(\"Reference Data for Input:\")\n",
    "    \n",
    "    # Load input data\n",
    "    inpdata = pd.read_csv(\"inputdata.csv\")\n",
    "    display(inpdata.head())\n",
    "\n",
    "    print(\"\\nLogistic regression built on the below X columns:\")\n",
    "    print(inpdata.columns)\n",
    "\n",
    "    print(\"\\n======================= Enter User Input Data ====================\")\n",
    "\n",
    "    # User Inputs\n",
    "    print(\"\\nEnter Institute Name:\")\n",
    "    print(inpdata['Institute Name'].unique())\n",
    "    insti = input(\"Select institute: \").strip()\n",
    "\n",
    "    print(\"\\nEnter Course Name:\")\n",
    "    print(inpdata['CourseName'].unique())\n",
    "    course = input(\"Select course: \").strip()\n",
    "\n",
    "    print(\"\\nEnter Followers:\")\n",
    "    followers = eval(input(f\"min-{inpdata['Followers'].min()}, max-{inpdata['Followers'].max()}: \"))\n",
    "\n",
    "    print(\"\\nEnter type of post:\")\n",
    "    print(inpdata['type'].unique())\n",
    "    typeofpost = input(\"Select type: \").strip()\n",
    "\n",
    "    print(\"\\nEnter Location:\")\n",
    "    print(inpdata['Location'].unique())\n",
    "    location = input(\"Select location: \").strip()\n",
    "\n",
    "    print(\"\\nEnter Day:\")\n",
    "    print(inpdata['Day'].unique())\n",
    "    day = input(\"Select day: \").strip()\n",
    "\n",
    "    # Create user input DataFrame\n",
    "    row = pd.DataFrame([[insti, course, followers, typeofpost, location, day]], columns=inpdata.columns)\n",
    "\n",
    "    print(\"\\nGiven User Input Data:\")\n",
    "    display(row)\n",
    "\n",
    "    ####### Data Pre-Processing #######\n",
    "\n",
    "    # Binary Encoding\n",
    "    row['type'].replace({'post': 0, 'reel': 1}, inplace=True)\n",
    "    row['Location'].replace({'hyderabad': 0, 'banglore': 1}, inplace=True)\n",
    "\n",
    "    # Check if Encoding Dictionaries Exist\n",
    "    try:\n",
    "        row['Day'].replace(Day_encoding, inplace=True)\n",
    "    except NameError:\n",
    "        print(\"\\nError: Day_encoding dictionary is missing.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        row['CourseName'].replace(CourseName_encoding, inplace=True)\n",
    "    except NameError:\n",
    "        print(\"\\nError: CourseName_encoding dictionary is missing.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        ohe = joblib.load('ohe.pkl')\n",
    "    \n",
    "        if isinstance(ohe, list):\n",
    "            ohe = ohe[0]  \n",
    "\n",
    "        # Get feature names\n",
    "        ohe_feature_names = ohe.get_feature_names_out().tolist()\n",
    "\n",
    "        # Transform the input data\n",
    "        row_ohe = ohe.transform(row[['Institute Name']])  \n",
    "        row_ohe = pd.DataFrame(row_ohe, columns=ohe_feature_names)\n",
    "\n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(\"\\nWarning: Given Institute Name is not in training data. Proceeding with all zeros.\")\n",
    "        row_ohe = pd.DataFrame(np.zeros((1, len(ohe.get_feature_names_out()))), columns=ohe.get_feature_names_out())\n",
    "        row = pd.concat([row.drop(['Institute Name'], axis=1), row_ohe], axis=1)\n",
    "\n",
    "    # Normalize Followers\n",
    "    row[['Followers']] = sc.transform(row[['Followers']])\n",
    "\n",
    "    # Ensure feature alignment with the trained model\n",
    "    expected_features = log.feature_names_in_\n",
    "    row = row.reindex(columns=feature_names, fill_value=0)\n",
    "\n",
    "\n",
    "    print(\"\\nProcessed features for prediction\")\n",
    "    print(\"********** Logistic Prediction ***********\")\n",
    "\n",
    "    # Prediction\n",
    "    try:\n",
    "        probs = log.predict_proba(row)[0]\n",
    "        print(probs)\n",
    "        for category, prob in zip(log.classes_, probs):\n",
    "            print(f\"{category}: {round(prob, 2)}\")\n",
    "\n",
    "        # Get highest probability category\n",
    "        global predicted_category\n",
    "        predicted_category = log.classes_[probs.argmax()]\n",
    "        print(\"\\nPredicted Category:\", predicted_category)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"\\nError during prediction:\", e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd503b1c-ddf3-4884-a724-e431a191d2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ReachinSocialMedia_Prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eafdd8b-7e9e-43c0-a4f7-699629034dcd",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed27084-44ff-48c9-9f3a-894ee3ac89a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2194efdf-7b40-494b-846b-a8585eb43481",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b1d4fa-d5fe-4369-99d9-d120a47e06ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xr = pd.concat([df, vdata['Reach']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e17a6c0-d0a9-43bb-a220-fca4226b6bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e443c95-217c-4aa5-8abf-4ffbf83ca609",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xr.to_csv(\"inputdata1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bef4745-9f2d-4227-8371-d535139625d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1e94b9-e1ae-44a4-bb53-ebc37a5fd6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X, vdata['Reach']], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ead3f7-9c37-4bea-b45e-a4a70454620e",
   "metadata": {},
   "source": [
    "Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afde6c93-bda5-4727-9747-6c3513ad79bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Reach'] = X['Reach'].replace({'low': 0, 'moderate': 1, 'high': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd0834b-084e-448a-b4be-2b8a5e66b016",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970c14b7-f31c-4418-a85b-a52e244b77f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=vdata[[\"Likes\",\"Share\",\"Comments\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfabb465",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd03ad7c-53f7-4fea-8346-e80c1b22e9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Reach'] = X['Reach'].replace({'low': 0, 'moderate': 1, 'high': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebda34b-2de4-4318-8902-4fdfad09e061",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c7ffae-4418-41cb-94f5-e79aa1ce1f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6f9843-ba03-42d0-b20f-d4950cddabd2",
   "metadata": {},
   "source": [
    "**4.3 Train_Test Split (Data Validation)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d63d15e-659c-4693-a4a2-eb26c6e26334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688f552b-9554-4d7f-beec-8e291518b6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "xtrainr, xtestr, ytrainr, ytestr = train_test_split(X, Y, test_size=0.20, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfda9c1c-c1fb-4b46-be9f-91eea17951b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Shapes\n",
    "xtrainr.shape, xtestr.shape, ytrainr.shape, ytestr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d4249c-c491-43f9-b0e3-91736222e9a2",
   "metadata": {},
   "source": [
    "* Data Used for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f920fd7f-dbe8-45eb-8ee8-bef6628f64fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(xtrainr.head())\n",
    "display(ytrainr.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8db2076-09b5-4c33-b381-76ba8898f113",
   "metadata": {},
   "source": [
    "* Data Used for Model Testing/Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347c37eb-9854-4a91-9ce2-e00eef946f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(xtestr.head())\n",
    "display(ytestr.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6358eb17-2d7a-49eb-b135-6b3bdaf94d58",
   "metadata": {},
   "source": [
    "**Model Selection & Python Libraries**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d73b3fb-a9a2-40c3-a5ac-17165d69d2ec",
   "metadata": {},
   "source": [
    "* We have output col data numeric, considering regression algorithms\n",
    "\n",
    "    - **Regression Models/Algorithms:**\n",
    "        * Linear Algorithms (when the data is linear to output (having correlation))\n",
    "            - Linear Regression\n",
    "            - Polynomial Regression\n",
    "            - Lasso & Ridge Regression\n",
    "\n",
    "        * Non-Linear Algorithms (when the data is non-linear to output (not having correlation) using classification algorithms)\n",
    "            - Decision Tree Regressor\n",
    "            - RandomForest Regressor\n",
    "            - Xgboost Regressor\n",
    "            - Support Vector Regressor\n",
    "            - K Nearest Neighbors Regressor\n",
    "            \n",
    "Note:\n",
    "    \n",
    "* Data we got is linear & non-linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f75470-2cec-4c31-a8d3-6e5ade1ad761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm Modules\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.multioutput import MultiOutputRegressor  \n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70f8430-5abb-4da7-9d0a-4fbb467ab351",
   "metadata": {},
   "source": [
    "**4.4 Modeling - Defining & Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b74810-c5fa-458f-956b-289410c05e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Linear Regression \n",
    "\n",
    "mlr =LinearRegression()\n",
    "\n",
    "# Polynomial Regression\n",
    "\n",
    "polyfeat = PolynomialFeatures(degree = 2)  # degree is hyperparam\n",
    "\n",
    "poly = LinearRegression()\n",
    "\n",
    "# Lasso (L1) & Ridge (L2)\n",
    "\n",
    "lasso = MultiOutputRegressor(Lasso(alpha=0.01))# alpha/lambda - hyperparam - penalty\n",
    "\n",
    "ridge = MultiOutputRegressor(Ridge(alpha=1))\n",
    "\n",
    "\n",
    "\n",
    "# KNN\n",
    "\n",
    "knnr = MultiOutputRegressor(KNeighborsRegressor(n_neighbors=5)) # n_neighbors - hyper param\n",
    "\n",
    "# Support Vector Regressor\n",
    "\n",
    "svr = MultiOutputRegressor(SVR(kernel='rbf'))\n",
    "# Decision Tree Regressor\n",
    "\n",
    "dtr = DecisionTreeRegressor()\n",
    "\n",
    "# Random Forest regressor \n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators=50,min_samples_split=2,min_samples_leaf=2,max_features='sqrt', max_depth= 20) # n_estimators - hyperparam - number of decision trees\n",
    "\n",
    "\n",
    "# Xgb\n",
    "\n",
    "xgbr = XGBRegressor(subsample= 0.6, n_estimators=500, max_depth=5, learning_rate=0.01, gamma=0,colsample_bytree= 0.6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f60e2df-aa86-4716-8554-b0986935b2b4",
   "metadata": {},
   "source": [
    "                                                    Training above defined models one by one\r\n",
    "\r\n",
    "                                                          (with xtrarin, ytrarin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf0a667-542f-45e4-8995-a9ec678be3ea",
   "metadata": {},
   "source": [
    "* We can use fit method on above objects to train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28b3d36-a8be-4496-9062-4a1828fa0fae",
   "metadata": {},
   "source": [
    "**4.4.1 Linear regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b881696-3aa4-41a5-9750-1d33968a643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "\n",
    "mlr.fit(xtrainr, ytrainr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db87344-2c97-4889-9a69-109fa72d9749",
   "metadata": {},
   "source": [
    "                                                        Model Params\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd816e0-9a65-4743-b0e3-47bca4749f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr.coef_, mlr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e16a357-404e-4fdb-81a7-c5f5addc64bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq = str(mlr.intercept_)\n",
    "\n",
    "for i,j in zip(xtrain.columns,mlr.coef_):\n",
    "    mx = '{}*{}'.format(i,j)\n",
    "    eq = eq+\" + \"+mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df72d815-4807-4534-a770-dd41f5a3f1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3242d7eb-e070-4508-8ea5-347ea3e1fa50",
   "metadata": {},
   "source": [
    "**4.4.2 Polynomial Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75f1bbf-0a3a-4004-8ccf-c38ca2c25a8c",
   "metadata": {},
   "source": [
    "**The Dimensionality will become more and will take heavy run time if\n",
    "we take all the inputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ce3bd4-30a8-42ee-a3f8-c33c35e86cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrainr.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c1e4a6-ed64-400f-8c30-c04d0fa17e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting x data to poly features\n",
    "\n",
    "xtrainr_poly = polyfeat.fit_transform(xtrainr) # fit_transform on train\n",
    "\n",
    "xtestr_poly = polyfeat.transform(xtestr) # transform on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e98d89a-5e19-4fd7-94c1-0ecebdf63a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrainr_poly.shape, xtestr_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6a3da9-b0ed-47b8-abd6-1dbbee54cb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Linear Regression to above polynomial features\n",
    "\n",
    "poly.fit(xtrainr_poly, ytrainr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b882e16-4e93-45a1-bd51-c9aae5a00662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "\n",
    "poly.coef_, poly.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b316751-22a0-44e8-b59e-99113d01edd3",
   "metadata": {},
   "source": [
    "**4.4.3 Lasso and Ridge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac0ff57-16bf-46d2-9919-fff008d2dd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "\n",
    "lasso.fit(xtrainr,ytrainr)\n",
    "ridge.fit(xtrainr,ytrainr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df849c69-e83e-4517-ac21-814dbeaee85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed9822d-0968-439f-8fdc-744ddf3e1fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge.estimators_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee021afd-a129-474d-9e7d-64f615a06019",
   "metadata": {},
   "source": [
    "**4.4.4 KNN Regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3785d28a-0a28-4361-8638-be7ce75eaa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "knnr.fit(xtrainr, ytrainr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5984f375-8df7-4dc6-a087-849f6679f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "knnr.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2c55c1-b242-4797-ae58-c0aedee64746",
   "metadata": {},
   "source": [
    "**4.4.5 Support Vector Regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cd01c5-eb33-4d24-bd39-fbf6c44475f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr.fit(xtrainr, ytrainr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f79307-f9fe-4178-b932-49198a44c0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5610f7a-4b90-452a-91dc-3f20ad16296d",
   "metadata": {},
   "source": [
    "**4.4.6 Decision Tree Regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a73d15-4ea0-4910-855b-d63bf124d369",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr.fit(xtrainr, ytrainr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06004624-32ee-4428-aea3-35201be0512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Params\n",
    "\n",
    "print(\"Model Params:\")\n",
    "print(dtr.get_params())\n",
    "print()\n",
    "print(\"Columns Importance:\")\n",
    "print()\n",
    "for i, j in zip(dtr.feature_names_in_, dtr.feature_importances_):\n",
    "    print(i+\": \"+str(round(j,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df43fe6f-9be7-44c4-b971-9c97df796872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree Visualization\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(18,18))\n",
    "plot_tree(dtr,filled=True,fontsize=8,feature_names=list(xtrainr.columns),max_depth=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23122efb-ae3a-49c3-a1f8-f9eb195b36b5",
   "metadata": {},
   "source": [
    "**4.4.7 Random Forest Regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddf4d31-03a4-415c-a429-27586d4ea155",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr.fit(xtrainr, ytrainr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1897a1ee-3189-4654-aa1c-fca38c06474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Params\n",
    "\n",
    "print(\"Model Params:\")\n",
    "print(rfr.get_params())\n",
    "print()\n",
    "print(\"Columns Importance:\")\n",
    "print()\n",
    "for i, j in zip(rfr.feature_names_in_, rfr.feature_importances_):\n",
    "    print(i+\": \"+str(round(j,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8df698-d9e4-4df8-a292-db9ac3e60911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Tree Visualization\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(18,18))\n",
    "plot_tree(rfr.estimators_[0],filled=True,fontsize=8,feature_names=list(xtrainr.columns),max_depth=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993a3863-0f5f-4631-9b1e-c2546f826174",
   "metadata": {},
   "source": [
    "**4.4.8 Xgb Regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd8b4e9-793d-49d0-8b85-95cabb02a14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "\n",
    "xgbr.fit(xtrainr, ytrainr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da35ea8f-9554-473f-bb43-20bef23ddfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d80bfb3-aadd-40a2-8dea-0b1826bb7098",
   "metadata": {},
   "source": [
    "****4.5 & 4.6 Predictions & Evaluations****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf008aa-9f97-4142-9f89-d72ccfe1c4ad",
   "metadata": {},
   "source": [
    "* Checking trained model performance with test data\n",
    "* Using xtest data we will be getting predictions, these predictions will be compared to ytest\n",
    "    - To compare we can use below metrics,\n",
    "        - Loss Metric: **RMSE**\n",
    "        - Score/Performance Metric: **R2Score**\n",
    "* **For regression models , we have following to check model performance**\n",
    "\n",
    "Technique | Outcome\n",
    "-------|-----------\n",
    "**Bias-Variance Trade Off**|Model Fitness Based on Train & Test Metrics\n",
    "**Crossvalidation**|Checking Trained model performance on entire X and y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d9dd93-f5fb-4bee-b850-0eed64dc09e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9628a2-b4f8-4d11-a041-e26c60e3f676",
   "metadata": {},
   "source": [
    "* Looping through each trained model for test predictions, & evalaution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56c9ff3-a05c-42d4-8ee4-1eaa7a6b94f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Multiple Linear Regression','Polynomial Regression','Lasso Regression','Ridge Regression',\n",
    "         'Knn Regressor', 'Svm Regressor', 'Decision Tree Regressor', 'RandomForest Regressor', 'Xgboost Regressor']\n",
    "models = {'mlr':mlr, 'poly':poly, 'lasso':lasso, 'ridge':ridge,  'knn':knnr, 'svm':svr, 'dt':dtr, 'rf':rfr, 'xgb':xgbr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd345255-266a-4ec6-80bd-2c0cc7bf5986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking User-Defined Module\n",
    "\n",
    "from mlevalr import regval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319bcc50-6e65-4ec3-9a50-7c95ade6a831",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainrmse, testrmse, trainr2, testr2, crossvalscore, fit = regval(xtrainr, xtrainr_poly, xtestr, xtestr_poly, ytrainr, ytestr, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783123d3-73d8-4dfc-a5ad-db0785e20bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Model Evaluation Table\n",
    "# Display Options for Table\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "display(pd.DataFrame({'Model':names, 'TrainRMSE':trainrmse, 'TestRMSE':testrmse,\n",
    "             'Trainscore':trainr2, 'Testscore':testr2, 'Crossvalscore':crossvalscore, 'Fit':fit}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37f3956-72b2-427d-87e7-7c868ea18a69",
   "metadata": {},
   "source": [
    "**4.7 Best Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fe84ff-fa37-49ab-8dfc-b4e3c644aabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking output col distribution\n",
    "\n",
    "Y.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ef7b49-cd02-4862-b327-d134d568805f",
   "metadata": {},
   "source": [
    "* By observing y col distribution it is clear that from the above table, test rmse values are very low for xgboost regressor\n",
    "* According to above table , we can select Xgboost Regressor is better performance model for this data (low test rmse , high r2score, matching cross val score to test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee865ce0-dab2-4fe0-891b-1ed3208c9271",
   "metadata": {},
   "source": [
    "**4.8 Hyp Param Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f29474-0fa7-4887-b8f2-0791f60fd2c4",
   "metadata": {},
   "source": [
    "**4.9 Saving Model**\n",
    "\n",
    "* Saving Trained & Evaluated model for future predictions\n",
    "    * From above training we need to save xgbr & ohe, sc objects\n",
    "    * In python we have libraries , joblib, pickle to save model files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbada897-6703-4021-861d-f0b28e1e6a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Saving trained model\n",
    "joblib.dump(xgbr, 'xgbr.pkl')\n",
    "# Saving onehot encoded model\n",
    "\n",
    "joblib.dump(ohe, 'ohe.pkl')\n",
    "\n",
    "joblib.dump(sc, \"sc.pkl\")\n",
    "\n",
    "trained_feature_names = X.columns.tolist()\n",
    "import pickle\n",
    "\n",
    "with open(\"feature_names.pkl\",\"wb\") as f:\n",
    "    pickle.dump(trained_feature_names,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fa75d3-6d7c-4518-98bd-86904dc5bb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading saved pickles and getting predictions\n",
    "\n",
    "import joblib\n",
    "xgbr= joblib.load('xgbr.pkl')\n",
    "feature_names = xgbr.feature_names_in_.tolist()\n",
    "\n",
    "\n",
    "sc = joblib.load(\"sc.pkl\")\n",
    "\n",
    "# Loading Saved object files\n",
    "ohe = joblib.load('ohe.pkl')\n",
    "   \n",
    "\n",
    "# Loading Saved Ordinal Encoded files\n",
    "with open('Day_encoding.pkl', 'rb') as f:\n",
    "    Day_encoding = pickle.load(f)\n",
    "    \n",
    "with open('CourseName_encoding.pkl', 'rb') as f:\n",
    "    CourseName_encoding = pickle.load(f)\n",
    "with open(\"feature_names.pkl\",'rb') as f:\n",
    "    trained_feature_names = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8307d5c2-267e-4043-8e55-afd568250039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def LCSofSocialMedia_Post():\n",
    "    print(\"Reference Data for Input:\")\n",
    "    \n",
    "    # Load input data\n",
    "    inpdata = pd.read_csv(\"inputdata1.csv\")\n",
    "    display(inpdata.head())\n",
    "\n",
    "    print(\"\\n Xgboost  regressor built on the below X columns:\")\n",
    "    print(inpdata.columns)\n",
    "\n",
    "    print(\"\\n======================= Enter User Input Data ====================\")\n",
    "\n",
    "    # User Inputs\n",
    "    print(\"\\nEnter Institute Name:\")\n",
    "    print(inpdata['Institute Name'].unique())\n",
    "    insti = input(\"Select institute: \").strip()\n",
    "\n",
    "    print(\"\\nEnter Course Name:\")\n",
    "    print(inpdata['CourseName'].unique())\n",
    "    course = input(\"Select course: \").strip()\n",
    "\n",
    "    print(\"\\nEnter Followers:\")\n",
    "    followers = eval(input(f\"min-{inpdata['Followers'].min()}, max-{inpdata['Followers'].max()}: \"))\n",
    "\n",
    "    print(\"\\nEnter type of post:\")\n",
    "    print(inpdata['type'].unique())\n",
    "    typeofpost = input(\"Select type: \").strip()\n",
    "\n",
    "    print(\"\\nEnter Location:\")\n",
    "    print(inpdata['Location'].unique())\n",
    "    location = input(\"Select location: \").strip()\n",
    "\n",
    "    print(\"\\nEnter Day:\")\n",
    "    print(inpdata['Day'].unique())\n",
    "    day = input(\"Select day: \").strip()\n",
    "\n",
    "    print(\"\\nEnter Reach:\")\n",
    "    print(inpdata['Reach'].unique())\n",
    "    reach = input(\"Select Reach: \").strip()\n",
    "\n",
    "    # Create user input DataFrame\n",
    "    row = pd.DataFrame([[insti, course, followers, typeofpost, location, day,reach]], columns=inpdata.columns)\n",
    "\n",
    "    print(\"\\nGiven User Input Data:\")\n",
    "    display(row)\n",
    "\n",
    "    ####### Data Pre-Processing #######\n",
    "\n",
    "    # Binary Encoding\n",
    "    row['type'].replace({'post': 0, 'reel': 1}, inplace=True)\n",
    "    row['Location'].replace({'hyderabad': 0, 'banglore': 1}, inplace=True)\n",
    "    row['Reach'].replace({'low': 0, 'moderate': 1,'high':2}, inplace=True)\n",
    "\n",
    "   # Ordinal Encoding\n",
    "    row['Day'].replace(Day_encoding, inplace=True)\n",
    "    row['CourseName'].replace(CourseName_encoding, inplace=True)\n",
    "    \n",
    "    \n",
    "    # One-Hot Encoding\n",
    "   \n",
    "    if 'Institute Name' in row.columns:\n",
    "        ohedata = ohe.transform(row[['Institute Name']]).toarray()\n",
    "        ohedata = pd.DataFrame(ohedata, columns=ohe.get_feature_names_out())\n",
    "\n",
    "   \n",
    "        # Add missing columns if necessary\n",
    "        missing_cols = set(trained_feature_names) - set(ohedata.columns)\n",
    "        for col in missing_cols:\n",
    "            ohedata[col] = 0  # Add missing columns with value 0\n",
    "\n",
    "    # Ensure column order matches training\n",
    "        ohedata = ohedata[trained_feature_names]\n",
    "\n",
    "    # Merge with X\n",
    "        X = pd.concat([row.drop(['Institute Name'], axis=1), ohedata], axis=1)\n",
    "    else:\n",
    "        raise KeyError(\"Column 'Institute Name' not found in DataFrame X. Available columns: \", row.columns)\n",
    "\n",
    "    #Scaling\n",
    "    row[['Followers']] = sc.transform(row[['Followers']])\n",
    "\n",
    "    # Ensure feature alignment with the trained model\n",
    "    expected_features = xgbr.feature_names_in_\n",
    "    row = row.reindex(columns=feature_names, fill_value=0)\n",
    "\n",
    "    print(\"\\nProcessed features for prediction\")\n",
    "    print(\"********** Xgboost Regressor ***********\")\n",
    "    \n",
    "    # Prediction\n",
    "    try:\n",
    "    # Predict Likes, Comments, and Shares\n",
    "       predicted_values = xgbr.predict(row)[0]\n",
    "    \n",
    "       print(\"Likes:\",round(predicted_values[0],2),\"Shares:\",round(predicted_values[1],2),\"Comments:\",round(predicted_values[2],2))\n",
    "\n",
    "    except Exception as e:\n",
    "      print(\"\\nError during prediction:\", e)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d019221a-384a-4b3f-97f5-9e575fd3d8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "LCSofSocialMedia_Post()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
